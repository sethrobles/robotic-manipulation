{"cells":[{"cellId":"fc18b651cd804f21a5d49386cc881de3","cell_type":"markdown","metadata":{"cell_id":"fc18b651cd804f21a5d49386cc881de3","deepnote_cell_type":"markdown"},"source":"# Basics of Automatic Differentiation\nFor instructions on how to run these tutorial notebooks, please see the [index](./index.ipynb).\n","block_group":"86bd015efd3947379b54c6d630d9ae6b"},{"cellId":"4d1db9af22314100933405384d13b438","cell_type":"markdown","metadata":{"cell_id":"4d1db9af22314100933405384d13b438","deepnote_cell_type":"markdown"},"source":"This notebook provides a short tutorial for automatic differentiation in Drake. It covers the automatic differentiation of\n- Basic Eigen/Numpy operations,\n- Dynamical system operations (state update, output calculation, etc.),\n- Sampled data from simulation rollout.","block_group":"7b75011908344107a1ddad3a0c2e5f65"},{"cellId":"e22b30c0004e433691327f38c464a638","cell_type":"markdown","metadata":{"cell_id":"e22b30c0004e433691327f38c464a638","deepnote_cell_type":"markdown"},"source":"### Eigen/Numpy Operations\n\nDrake uses Eigen's AutoDiffScalar for automatic differentiation. Any explicit Eigen (and hence Numpy in Python) operations can be automatically differentiated. Let's consider the simple example $\\mathbf{y} = \\mathbf{a}^{\\top} \\mathbf{x} = [1,~ 2] \\mathbf{x}$. We want to obtain the derivative $\\partial \\mathbf{y} / \\partial \\mathbf{x} = \\mathbf{a}^{\\top}$ using automatic differentiation. Here is how to do it:","block_group":"39f68cbe2a97479187bde4edf8de6a9d"},{"cellId":"b38b84aec3694197a1f09d11293fc670","cell_type":"code","metadata":{"source_hash":"9ebd70d9","execution_start":1758051676885,"execution_millis":149,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"b38b84aec3694197a1f09d11293fc670","deepnote_cell_type":"code"},"source":"import numpy as np\nfrom pydrake.autodiffutils import InitializeAutoDiff, ExtractGradient\n\na = np.array([1, 2]).reshape([2, -1])\nx = np.random.rand(2, 1)\nprint(\"double type array:\\n\", x)\nx = InitializeAutoDiff(x)\nprint(\"converted to AutoDiffXd scalar type array:\\n\", x)\ny = a.T @ x\ndydx = ExtractGradient(y)\nprint(\"Gradient:\", ExtractGradient(y))\nnp.testing.assert_allclose(a.T, dydx)  # assert dy/dx = a^T","block_group":"02658b810cce4804836903dc0c1b291f","execution_count":1,"outputs":[{"name":"stdout","text":"double type array:\n [[0.21713032]\n [0.74129513]]\nconverted to AutoDiffXd scalar type array:\n [[<AutoDiffXd 0.21713032349833472 nderiv=2>]\n [<AutoDiffXd 0.7412951251455184 nderiv=2>]]\nGradient: [[1. 2.]]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/72dbcb6a-a101-4728-a628-e513840e6f46","content_dependencies":null},{"cellId":"4b4dbdc6dab14dfd808ceca95477455d","cell_type":"markdown","metadata":{"cell_id":"4b4dbdc6dab14dfd808ceca95477455d","deepnote_cell_type":"markdown"},"source":"Note that for automatic differentiation, we just need two extra steps in addition to the usual explicit Numpy operations: 1) Declare the variable with respect to which we want to differentiate using `InitializeAutoDiff(x)`, and 2) extract the gradient in the end using `ExtractGradient(y)`.\n\nWe can also differentiate w.r.t. multiple variables. Consider the example $\\mathbf{y} = \\mathbf{a}_1^{\\top} \\mathbf{x}_1 + \\mathbf{a}_2^{\\top} \\mathbf{x}_2$, where we want to obtain $\\partial \\mathbf{y} / \\partial \\mathbf{x}_1$ and $\\partial \\mathbf{y} / \\partial \\mathbf{x}_2$. Here is how to do it:","block_group":"ae9ae188692245d5907d819cc5214983"},{"cellId":"c5a1022ce797453c8cee6a71ab5aad7e","cell_type":"code","metadata":{"source_hash":"e0b153af","execution_start":1758051677086,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"c5a1022ce797453c8cee6a71ab5aad7e","deepnote_cell_type":"code"},"source":"import numpy as np\nfrom pydrake.autodiffutils import InitializeAutoDiffTuple, ExtractGradient\n\na1 = np.array([1, 2]).reshape([2, -1])\nx1 = np.random.rand(2, 1)\n\na2 = np.array([1, 2, 3]).reshape([3, -1])\nx2 = np.random.rand(3, 1)\n\nx1, x2 = InitializeAutoDiffTuple(x1, x2)\ny = a1.T @ x1+ a2.T @ x2\n\ndydx = ExtractGradient(y)\nprint(\"All gradients:\", dydx)\ndydx1 = dydx[0][0:2]\ndydx2 = dydx[0][2:]\nprint(\"Gradients calculated by automatic differentiation:\")\nprint(\"a1^T =\", dydx1)\nnp.testing.assert_allclose(a1.T, [dydx1])\nprint(\"a2^T =\", dydx2)\nnp.testing.assert_allclose(a2.T, [dydx2])","block_group":"392551473e2e43a898b264e09560b519","execution_count":2,"outputs":[{"name":"stdout","text":"All gradients: [[1. 2. 1. 2. 3.]]\nGradients calculated by automatic differentiation:\na1^T = [1. 2.]\na2^T = [1. 2. 3.]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/4deeb8eb-3643-4b86-8c35-426e4b5dc4ad","content_dependencies":null},{"cellId":"45ae549a1a78425d9d2b078307968655","cell_type":"markdown","metadata":{"cell_id":"45ae549a1a78425d9d2b078307968655","deepnote_cell_type":"markdown"},"source":"Note that `ExtractGradient(y)` extracts derivatives of `y` with respect to _all_ variables declared by `InitializeAutodiffTuple`.","block_group":"bd0975537da242618aae7c8920956768"},{"cellId":"6642b0a979eb432e896e2693d858bc98","cell_type":"markdown","metadata":{"cell_id":"6642b0a979eb432e896e2693d858bc98","deepnote_cell_type":"markdown"},"source":"## Dynamical Systems","block_group":"c7e0f80869a3497dbdbea19bfab3bd2d"},{"cellId":"0a4b837d2b3d4465bc1fa7e80b5a45c2","cell_type":"markdown","metadata":{"cell_id":"0a4b837d2b3d4465bc1fa7e80b5a45c2","deepnote_cell_type":"markdown"},"source":"### Drake's Built-in Dynamical Systems\n\nDrake's most built-in systems' dynamics only involve explicit Eigen operations. Hence, they are all automatically differentiable. Let's consider the simple discrete-time [LinearSystem](https://drake.mit.edu/doxygen_cxx/classdrake_1_1systems_1_1_linear_system.html), whose dynamics is given as\n$$x_{t+1} = x_t +  2u_t, ~~~y_{t} = 3x_t + 4u_t.$$\nFor general dynamical systems, the derivatives of next state w.r.t. state $\\partial x_{t+1}/ \\partial x_t$ and input $\\partial x_{t+1}/ \\partial u_t$, and output w.r.t. state $\\partial y_{t}/ \\partial x_t$ and input $\\partial y_{t}/ \\partial u_t$ are frequently wanted. Here we will show how to obtain them via automatic differentiation. Let's first construct the system:","block_group":"cdcd79f5a1ad4326875d9727d982c04e"},{"cellId":"dc4a901ceb254d3ca5f9faec95a75d56","cell_type":"code","metadata":{"source_hash":"a359fa45","execution_start":1758051677135,"execution_millis":95,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"dc4a901ceb254d3ca5f9faec95a75d56","deepnote_cell_type":"code"},"source":"import numpy as np\nfrom pydrake.systems.primitives import LinearSystem\nfrom pydrake.autodiffutils import InitializeAutoDiffTuple, ExtractGradient\n\nA = np.array([[1]])\nB = np.array([[2]])\nC = np.array([[3]])\nD = np.array([[4]])\ntimestep = 1  # so that the system is discrete-time\nsystem = LinearSystem(A, B, C, D, timestep)\n\nprint(\"A system using double:\", system)","block_group":"7fda6b408d4041b9869877dd7e43f34b","execution_count":3,"outputs":[{"name":"stdout","text":"A system using double: <pydrake.systems.primitives.LinearSystem object at 0x7f0fc41d3d10>\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/bc527a91-93cb-4f7f-8b55-a857f6c23913","content_dependencies":null},{"cellId":"3148e81630be4c9c8b3f0bf50582609c","cell_type":"markdown","metadata":{"cell_id":"3148e81630be4c9c8b3f0bf50582609c","deepnote_cell_type":"markdown"},"source":"By default, the system uses `double` as the scalar type. We need to convert it to use [drake::AutoDiffXd](https://drake.mit.edu/doxygen_cxx/namespacedrake.html#a35725b277b02aeb79f24fd7f724e6dbc):","block_group":"1f4e54d7507e4a158fcddd8d13554e0b"},{"cellId":"694e0b5d30574e258748533662fbaf49","cell_type":"code","metadata":{"source_hash":"bf2edcba","execution_start":1758051677285,"execution_millis":1,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"694e0b5d30574e258748533662fbaf49","deepnote_cell_type":"code"},"source":"system_ad = system.ToAutoDiffXd()\nprint(\"The system converted to AutoDiffXd:\", system_ad)","block_group":"81495246b2d74a8fa7691e00f6686d92","execution_count":4,"outputs":[{"name":"stdout","text":"The system converted to AutoDiffXd: <pydrake.systems.primitives.LinearSystem_ð“£AutoDiffXdð“¤ object at 0x7f0fcc1dcf50>\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/a209a32c-1c2e-4bcf-a997-9891f81a34a2","content_dependencies":null},{"cellId":"84bf5cfae2aa4e8d80d124b5a8bc4bed","cell_type":"markdown","metadata":{"cell_id":"84bf5cfae2aa4e8d80d124b5a8bc4bed","deepnote_cell_type":"markdown"},"source":"Let's set $x_t = 1$ and $u_t=1$ (or any real numbers)","block_group":"e36459bbf7f8455f820db0cd482467ab"},{"cellId":"b2c801eab9264bcb83c455709d9aca6c","cell_type":"code","metadata":{"source_hash":"1634c8bf","execution_start":1758051677355,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"b2c801eab9264bcb83c455709d9aca6c","deepnote_cell_type":"code"},"source":"context_ad = system_ad.CreateDefaultContext()\nx = np.array([1])\nu = np.array([1])\nx, u = InitializeAutoDiffTuple(x, u)\ncontext_ad.SetDiscreteState(0, x)\nsystem_ad.get_input_port(0).FixValue(context_ad, u)","block_group":"ba300bcee00440e2be12e401f381aef7","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<pydrake.systems.framework.FixedInputPortValue at 0x7f0fc793a870>"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/7d907d3e-0667-46b8-b65c-70a406581fc6","content_dependencies":null},{"cellId":"30d1553476b14d5e867e955a6758adb8","cell_type":"markdown","metadata":{"cell_id":"30d1553476b14d5e867e955a6758adb8","deepnote_cell_type":"markdown"},"source":"Then, we calculate the derivatives of next states $\\partial x_{t+1}/ \\partial x_t=1$ and $\\partial x_{t+1}/ \\partial u_t=2$","block_group":"4b840c542f17415181c45cd79bf33454"},{"cellId":"8a1419659ef24a8fb9175f296239ead9","cell_type":"code","metadata":{"source_hash":"28d268d2","execution_start":1758051677405,"execution_millis":1,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"8a1419659ef24a8fb9175f296239ead9","deepnote_cell_type":"code"},"source":"# allocate the state object\nx_next_object = system_ad.AllocateContext().get_discrete_state()  \n# store value to x_next_object without modifying context\nsystem_ad.CalcForcedDiscreteVariableUpdate(context_ad, x_next_object)  \n# to extract numpy array from the state object\nx_next = x_next_object.get_vector(0).CopyToVector()  \ngrad = ExtractGradient(x_next)\ndx_next_dx = grad.flatten()[0]\ndx_next_du = grad.flatten()[1]\n\nprint(\"Gradients calculated by automatic differentiation:\")\nprint(\"dx'/dx =\", dx_next_dx)\nassert dx_next_dx == 1\nprint(\"dx'/du =\", dx_next_du)\nassert dx_next_du == 2","block_group":"55c95eb3d6374006bc9c8d31bb68bb85","execution_count":6,"outputs":[{"name":"stdout","text":"Gradients calculated by automatic differentiation:\ndx'/dx = 1.0\ndx'/du = 2.0\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/451a721e-48da-4174-88d6-be32d749c59a","content_dependencies":null},{"cellId":"7a295989eb0c41d78d733b292ad559c4","cell_type":"markdown","metadata":{"cell_id":"7a295989eb0c41d78d733b292ad559c4","deepnote_cell_type":"markdown"},"source":"and the derivatives of output $\\partial y_{t}/ \\partial x_t=3$ and $\\partial x_{t}/ \\partial u_t=4$","block_group":"8433d054d7a24e119384ed42b18f790d"},{"cellId":"b781728541804630a89b026500833aab","cell_type":"code","metadata":{"source_hash":"ba473e73","execution_start":1758051677465,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"b781728541804630a89b026500833aab","deepnote_cell_type":"code"},"source":"output_object = system_ad.AllocateOutput()\nsystem_ad.CalcOutput(context_ad, output_object)\noutput_port_index = system_ad.get_output_port(0).get_index()\noutput = output_object.get_vector_data(output_port_index).CopyToVector()\ngrad = ExtractGradient(output)\ndy_dx = grad.flatten()[0]\ndy_du = grad.flatten()[1]\nprint(\"Gradients calculated by automatic differentiation::\")\nprint(\"dy/dx =\", dy_dx)\nassert dy_dx == 3\nprint(\"dy/du =\", dy_du)\nassert dy_du == 4","block_group":"cb21091608cb42758c5bc777221f2785","execution_count":7,"outputs":[{"name":"stdout","text":"Gradients calculated by automatic differentiation::\ndy/dx = 3.0\ndy/du = 4.0\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/952c7d77-1c04-4e8f-8ea5-4d7e60356f0b","content_dependencies":null},{"cellId":"6ff1b3b41fea42ca8a4a02920afc20ce","cell_type":"markdown","metadata":{"cell_id":"6ff1b3b41fea42ca8a4a02920afc20ce","deepnote_cell_type":"markdown"},"source":"### Write Your Own Dynamical Systems for Automatic Differentiation","block_group":"bf750d18e7864fcf840d1b07053d114d"},{"cellId":"d62d229836964d94bd7957dc40eb987c","cell_type":"markdown","metadata":{"cell_id":"d62d229836964d94bd7957dc40eb987c","deepnote_cell_type":"markdown"},"source":"You can write your own [LeafSystem](https://drake.mit.edu/doxygen_cxx/classdrake_1_1systems_1_1_leaf_system.html) that supports automatic differentiation by using the [drake::AutoDiffXd](https://drake.mit.edu/doxygen_cxx/namespacedrake.html#a35725b277b02aeb79f24fd7f724e6dbc) scalar type as the template value. In Python, you can do so using the [TemplateSystem](https://drake.mit.edu/pydrake/pydrake.systems.scalar_conversion.html) utility. Let's consider the simple discrete-time system \n$$x_{t+1} = x_t +  2u_t, ~~~y_{t} = x^2_t.$$\nWe will build it with a discrete-time [LinearSystem](https://drake.mit.edu/doxygen_cxx/classdrake_1_1systems_1_1_linear_system.html), and a custom system that squares the input as the output. Let's first define the linear system $x_{t+1} = x_t +  2u_t, ~~~y_{t} = x_t$:","block_group":"129a1fb120e0416e9bc64d349d4e7feb"},{"cellId":"ca6f800b25204e30aef7e7e0c8dd3dac","cell_type":"code","metadata":{"source_hash":"78d10a4e","execution_start":1758051677525,"execution_millis":1,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"ca6f800b25204e30aef7e7e0c8dd3dac","deepnote_cell_type":"code"},"source":"import numpy as np\nfrom pydrake.systems.scalar_conversion import TemplateSystem\nfrom pydrake.systems.primitives import LinearSystem\nfrom pydrake.systems.framework import (\n    BasicVector_,\n    DiagramBuilder,\n    LeafSystem_,\n)\nfrom pydrake.autodiffutils import InitializeAutoDiffTuple, ExtractGradient\n\nA = np.array([[1]])\nB = np.array([[2]])\nC = np.array([[1]])\nD = np.array([[0]])\ntimestep = 1\nlinear_system = LinearSystem(A, B, C, D, timestep)","block_group":"be1c80abdf7a49aeafc7ea02e5161e76","execution_count":8,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"039680302f0141da8883b8169f82e356","cell_type":"markdown","metadata":{"cell_id":"039680302f0141da8883b8169f82e356","deepnote_cell_type":"markdown"},"source":"Now, let's define the templated custom system:","block_group":"c42f4ba4a9f84092a4823b5dd110889f"},{"cellId":"014b632045a9410d8519d927d0bde0ed","cell_type":"code","metadata":{"source_hash":"2c87ea7a","execution_start":1758051677586,"execution_millis":140,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"014b632045a9410d8519d927d0bde0ed","deepnote_cell_type":"code"},"source":"@TemplateSystem.define(\"SquareSystem_\")\ndef SquareSystem_(T):\n    class Impl(LeafSystem_[T]):\n        def _construct(self, dimension: int, converter=None):\n            LeafSystem_[T].__init__(self, converter=converter)\n            self.dimension = dimension\n            self.input_port = self.DeclareVectorInputPort(\n                \"input\", BasicVector_[T](dimension)\n            )\n            self.output_port = self.DeclareVectorOutputPort(\n                \"output\",\n                BasicVector_[T](dimension),\n                self.calc_output,\n            )\n\n        def _construct_copy(self, other, converter=None):\n            Impl._construct(self, other.dimension, converter=converter)\n\n        def calc_output(self, context, output):\n            input_array = self.input_port.Eval(context)\n            # Element-wise squared input as the output y = x * x\n            output.set_value(input_array * input_array)\n\n    return Impl\n\nSquareSystem = SquareSystem_[None]  # The default system that uses double as the scalar","block_group":"1b1885e0834245a4b0e3031189f506d9","execution_count":9,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"2b22477ccfaf4d31b653d86e3f0b606e","cell_type":"markdown","metadata":{"cell_id":"2b22477ccfaf4d31b653d86e3f0b606e","deepnote_cell_type":"markdown"},"source":"The main difference from what we saw in [Modeling Dynamical Systems](./dynamical_systems.ipynb) is the use of template classes `LeafSystem_[T]` and `BasicVector_[T]`. The default `double`-scalar class, defined as `SquareSystem = SquareSystem_[None]`, is nearly identical to a version defined without using template classes. However, by templating the system, Drake can automatically convert it to use [drake::AutoDiffXd](https://drake.mit.edu/doxygen_cxx/namespacedrake.html#a35725b277b02aeb79f24fd7f724e6dbc) for automatic differentiation. Now letâ€™s construct the custom system and compose the full diagram:","block_group":"6236170da998493b93a4ede267f18f36"},{"cellId":"6f5ac0cc93314906a0a06a7b4feb5a62","cell_type":"code","metadata":{"source_hash":"e29fd421","execution_start":1758051677775,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"6f5ac0cc93314906a0a06a7b4feb5a62","deepnote_cell_type":"code"},"source":"squared_output = SquareSystem(dimension=1)","block_group":"91f0fd5adf3b4bec915a58c6f14edfda","execution_count":10,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"b136a22963d94ca0b34fe072a567d1f1","cell_type":"code","metadata":{"source_hash":"ada60f1d","execution_start":1758051677835,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"b136a22963d94ca0b34fe072a567d1f1","deepnote_cell_type":"code"},"source":"builder = DiagramBuilder()\nbuilder.AddSystem(linear_system)\nbuilder.AddSystem(squared_output)\nbuilder.Connect(linear_system.get_output_port(0), squared_output.get_input_port(0))\nbuilder.ExportInput(linear_system.get_input_port(), \"input\")\nbuilder.ExportOutput(squared_output.get_output_port(), \"output\")\n# The full dynamical system we are considering\nsystem = builder.Build()  \nprint(\"Default double systems:\\n\", system.GetSystems())","block_group":"9c05481cd2894889bc8be67bb970b673","execution_count":11,"outputs":[{"name":"stdout","text":"Default double systems:\n [<pydrake.systems.primitives.LinearSystem object at 0x7f0fc41d3cb0>, <pydrake.systems.scalar_conversion.SquareSystem_ð“£floatð“¤ object at 0x7f0fba2399d0>]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/426dad90-88dd-40be-8174-bcd9a82728fa","content_dependencies":null},{"cellId":"775ac1ce942c4355b1a49fc68341a789","cell_type":"markdown","metadata":{"cell_id":"775ac1ce942c4355b1a49fc68341a789","deepnote_cell_type":"markdown"},"source":"Note that although we only construct the default `SquareSystem` that uses `double` as the scalar, it can be converted into a system using [AutoDiffXd](https://drake.mit.edu/doxygen_cxx/namespacedrake.html#a35725b277b02aeb79f24fd7f724e6dbc) as the scalar when we do `ToAutoDiffXd()`:","block_group":"474cdc40a512499f8b4d86ee207edb32"},{"cellId":"5a66580de5e7440282f0cebb4f07d156","cell_type":"code","metadata":{"source_hash":"3d5e20f7","execution_start":1758051677896,"execution_millis":1,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"5a66580de5e7440282f0cebb4f07d156","deepnote_cell_type":"code"},"source":"system_ad = system.ToAutoDiffXd()\nprint(\"AutoDiffXd systems:\\n\", system_ad.GetSystems())","block_group":"a5a499e29bca45e6b46f4ad36d68bbac","execution_count":12,"outputs":[{"name":"stdout","text":"AutoDiffXd systems:\n [<pydrake.systems.primitives.LinearSystem_ð“£AutoDiffXdð“¤ object at 0x7f0fba239e50>, <pydrake.systems.scalar_conversion.SquareSystem_ð“£AutoDiffXdð“¤ object at 0x7f0fba239c10>]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/50dccec5-de24-4393-b0ee-d97ca727d79c","content_dependencies":null},{"cellId":"9991c416edc64c02af0ca34d642ef8f0","cell_type":"markdown","metadata":{"cell_id":"9991c416edc64c02af0ca34d642ef8f0","deepnote_cell_type":"markdown"},"source":"Now let's calculate the derivatives at $x_t=1$ and $u_t=1$:","block_group":"36b29d6d92a447a8b7bafef6cdef9297"},{"cellId":"df3aa9f0f7ef45ffaaef211173a6d594","cell_type":"code","metadata":{"source_hash":"1634c8bf","execution_start":1758051677965,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"df3aa9f0f7ef45ffaaef211173a6d594","deepnote_cell_type":"code"},"source":"context_ad = system_ad.CreateDefaultContext()\nx = np.array([1])\nu = np.array([1])\nx, u = InitializeAutoDiffTuple(x, u)\ncontext_ad.SetDiscreteState(0, x)\nsystem_ad.get_input_port(0).FixValue(context_ad, u)","block_group":"254008ddcce24be78710f6ac5c3b3516","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<pydrake.systems.framework.FixedInputPortValue at 0x7f0fc792c1b0>"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/e3629b9a-0180-4ab9-b92e-da228c5bbbb0","content_dependencies":null},{"cellId":"3c2d9e19d3564436a5ce842cd352f636","cell_type":"markdown","metadata":{"cell_id":"3c2d9e19d3564436a5ce842cd352f636","deepnote_cell_type":"markdown"},"source":"We obtain the correct derivatives $\\left. \\partial y_{t}/ \\partial x_t \\right|_{x_t=1}= \\left. 2 x_t \\right|_{x_t=1} = 2$ and $\\partial y_{t}/ \\partial u_t=0$:","block_group":"f8ce7a782df14e3b96d08554738c4070"},{"cellId":"9b89b353fde64c56b73fee8f1f0304ad","cell_type":"code","metadata":{"source_hash":"a3951c4e","execution_start":1758051678015,"execution_millis":1,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"9b89b353fde64c56b73fee8f1f0304ad","deepnote_cell_type":"code"},"source":"output_object = system_ad.AllocateOutput()\nsystem_ad.CalcOutput(context_ad, output_object)\noutput_port_index = system_ad.GetOutputPort(\"output\").get_index()\noutput = output_object.get_vector_data(output_port_index).CopyToVector()\ngrad = ExtractGradient(output)\ndy_dx = grad.flatten()[0]\ndy_du = grad.flatten()[1]\nprint(\"Gradients calculated by automatic differentiation:\")\nprint(\"dy/dx =\", dy_dx)\nassert dy_dx == 2\nprint(\"dy/du =\", dy_du)\nassert dy_du == 0","block_group":"36eb5cf409f1406abefa88f60c066337","execution_count":14,"outputs":[{"name":"stdout","text":"Gradients calculated by automatic differentiation:\ndy/dx = 2.0\ndy/du = 0.0\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/55ffb8f5-2926-48ed-9aa9-9750cf6ead63","content_dependencies":null},{"cellId":"6b33ffbea88645d5baaf42c7658d3ec3","cell_type":"markdown","metadata":{"cell_id":"6b33ffbea88645d5baaf42c7658d3ec3","deepnote_cell_type":"markdown"},"source":"## Simulation Rollouts","block_group":"ecb9c810dbf04d76a137ac7a74f3617f"},{"cellId":"4dcf9862d75844aaa1806162ecf1b63c","cell_type":"markdown","metadata":{"cell_id":"4dcf9862d75844aaa1806162ecf1b63c","deepnote_cell_type":"markdown"},"source":"Lastly, let's simulate a continuous-time system, and differentiate the sampled simulation results. We consider the linear system\n$$ \\dot{x} = -x,~~ y = x.$$\nGiven the initial state $x_0$, its output solution is given as\n$$ y(t) = e^{-t} x_0,$$\nand the output's derivative w.r.t. the initial state is given as \n$$ \\frac{\\partial y}{\\partial x_0} = e^{-t},$$\nwhich only depends on time. Now we will calculate this derivative through automatic differentiation, and compare the results to the analytical gradients:","block_group":"193c59e2523147fda774d0b0511799e7"},{"cellId":"4cf179dba0f74eb3a245779af69cdc6c","cell_type":"code","metadata":{"source_hash":"39ea430","execution_start":1758051678065,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"4cf179dba0f74eb3a245779af69cdc6c","deepnote_cell_type":"code"},"source":"import numpy as np\ndef calculate_analytical_gradient(t):\n    return np.exp(-t)","block_group":"8c1b66885df64b9cb59f2a43266a9e0d","execution_count":15,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"d899a0c382854fb18ca57a3fedc8ce1d","cell_type":"markdown","metadata":{"cell_id":"d899a0c382854fb18ca57a3fedc8ce1d","deepnote_cell_type":"markdown"},"source":"Let's construct the linear system","block_group":"bfd16943422d424e9bfc7a700f187143"},{"cellId":"db148a90d40242e19824c3b7869664bd","cell_type":"code","metadata":{"source_hash":"2c97a94a","execution_start":1758051678118,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"db148a90d40242e19824c3b7869664bd","deepnote_cell_type":"code"},"source":"from pydrake.systems.primitives import LinearSystem, LogVectorOutput\nfrom pydrake.systems.framework import DiagramBuilder\nfrom pydrake.autodiffutils import InitializeAutoDiff, ExtractGradient, AutoDiffXd\nfrom pydrake.systems.analysis import Simulator_\n\nA = np.array([[-1]])\nB = np.array([[0]])\nC = np.array([[1]])\nD = np.array([[0]])\ntimestep = 0  # so that the system is continuous-time\nlinear_system = LinearSystem(A, B, C, D, timestep)\n\nbuilder = DiagramBuilder()\nbuilder.AddSystem(linear_system)\nbuilder.ExportInput(linear_system.get_input_port(), \"input\")\nbuilder.ExportOutput(linear_system.get_output_port(), \"output\")\nlogger = LogVectorOutput(linear_system.get_output_port(), builder, publish_period=0.1)\nsystem = builder.Build()  # The dynamical system we are considering","block_group":"80abb932164643cc9553b8ab0405f6da","execution_count":16,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"a21fbe05151b487b86068c592c08f95e","cell_type":"markdown","metadata":{"cell_id":"a21fbe05151b487b86068c592c08f95e","deepnote_cell_type":"markdown"},"source":"and convert it to use `AutoDiffXd` scalar","block_group":"d08db3ab686e46b4a2816146f67f8621"},{"cellId":"3e03804f2fac435b9105cb693a06f905","cell_type":"code","metadata":{"source_hash":"99f3ad0d","execution_start":1758051678165,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"3e03804f2fac435b9105cb693a06f905","deepnote_cell_type":"code"},"source":"system_ad = system.ToAutoDiffXd()\nlogger_ad = system_ad.GetSystems()[1]","block_group":"002594e75d4044558439c412d5a18199","execution_count":17,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"fc9da694a39d47c7b8f56b7b102e0621","cell_type":"markdown","metadata":{"cell_id":"fc9da694a39d47c7b8f56b7b102e0621","deepnote_cell_type":"markdown"},"source":"We get the `AutoDiffXd` version of the logger to extract the simulation results later. Now we construct a `Simulator` that uses `AutoDiffXd` scalar, and set an arbitrary initial state $x_0 = 5$:","block_group":"0a94790181cc4537927d21bf9ff174cc"},{"cellId":"720f4b359f064503abe8d00b107040d2","cell_type":"code","metadata":{"source_hash":"f18b838d","execution_start":1758051678215,"execution_millis":1,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"720f4b359f064503abe8d00b107040d2","deepnote_cell_type":"code"},"source":"simulator_ad = Simulator_[AutoDiffXd](system_ad)\ncontext_ad = simulator_ad.get_mutable_context()\nsystem_ad.get_input_port(0).FixValue(context_ad, 0)\nx0 = np.array([5])\nx0 = InitializeAutoDiff(x0)\ncontext_ad.SetContinuousState(x0)\nsimulator_ad.Initialize()","block_group":"c705b9f3022d4d44850374519998818e","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"<pydrake.systems.analysis.SimulatorStatus at 0x7f0fc412d2f0>"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/23db0441-4d75-4489-b3b6-f563ff4a72bd","content_dependencies":null},{"cellId":"6d1a128cae964b3c997b7556c397ebed","cell_type":"markdown","metadata":{"cell_id":"6d1a128cae964b3c997b7556c397ebed","deepnote_cell_type":"markdown"},"source":"Finally, we simulate for 1 second, and assert that the derivatives calculated by automatic differentiation match the analytical ones:","block_group":"74b22673760f4244b995a679d5758735"},{"cellId":"0cc7bb05802d429a84b42dcc4c01e833","cell_type":"code","metadata":{"source_hash":"72ea5333","execution_start":1758051678275,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"0cc7bb05802d429a84b42dcc4c01e833","deepnote_cell_type":"code"},"source":"simulator_ad.AdvanceTo(1)\nlog = logger_ad.FindLog(simulator_ad.get_context())\n# convert AutoDiffXd back to double\nsample_times = np.array([t.value() for t in log.sample_times()])\n# calcualte gradients analytically and via autodiff\nanalytical_gradients = calculate_analytical_gradient(sample_times)\nautodiff_gradients = ExtractGradient(log.data()).flatten()\n# Let's print the data at an arbitrary sample time\nsample_index = 3\nprint(\"dy/dx0 at t =\", sample_times[sample_index]),\nprint(\"Analytical gradient:\", analytical_gradients[sample_index])\nprint(\"Gradient calculated by autodiff:\", autodiff_gradients[sample_index])\n# We assert that the autodiff gradients are correct at all sample times\nnp.testing.assert_allclose(autodiff_gradients, analytical_gradients, atol=1e-6)","block_group":"4a2eb1423ac44791999f6a8989b37217","execution_count":19,"outputs":[{"name":"stdout","text":"dy/dx0 at t = 0.30000000000000004\nAnalytical gradient: 0.7408182206817179\nGradient calculated by autodiff: 0.7408182212987496\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c807740c-c82e-442f-af60-6f1f9932319e","content_dependencies":null},{"cellId":"c804f80a72254d89884e06b4a738223f","cell_type":"markdown","metadata":{"cell_id":"c804f80a72254d89884e06b4a738223f","deepnote_cell_type":"markdown"},"source":"## Further reading\n\n**System Scalar Types and Conversions in Drake**  \n- [Default Scalars](https://drake.mit.edu/doxygen_cxx/group__default__scalars.html): Overview of the scalar types commonly used in Drake, such as `double`, `AutoDiffXd`, and `symbolic::Expression`.  \n- [System Scalar Conversion](https://drake.mit.edu/doxygen_cxx/group__system__scalar__conversion.html): Describes how Drake systems support conversions between scalar types to enable features like automatic differentiation and symbolic analysis.\n\n**Automatic Differentiation with Eigen**  \n- [An Introduction to Automatic Differentiation in Eigen (PDF)](https://github.com/edrumwri/drake/blob/bbc944fec87f7dac13169c65c961db29906435fb/drake/doc/autodiff_intro/autodiff.pdf)\n\n**Automatic Differentiation with Drakeâ€™s Hydroelastic Contact Model**  \n- *Kurtz, V., & Lin, H.* (2022). Contact-Implicit Trajectory Optimization with Hydroelastic Contact and iLQR. *IEEE/RSJ IROS 2022*. [link](https://ieeexplore.ieee.org/abstract/document/9981686) [code](https://github.com/vincekurtz/drake_ddp)","block_group":"cc66cd5550f8441baa79f7469889ba19"},{"cellId":"07eea4550d2d4372a351586aff3310af","cell_type":"code","metadata":{"source_hash":"b623e53d","execution_start":1758051678335,"execution_millis":0,"execution_context_id":"d91ddf9a-0d98-4658-b81c-aba68f975758","cell_id":"07eea4550d2d4372a351586aff3310af","deepnote_cell_type":"code"},"source":"","block_group":"11aaa94c020641f5acc8084f40b3f1a9","execution_count":20,"outputs":[],"outputs_reference":null,"content_dependencies":null}],
        "metadata": {"deepnote_notebook_id":"90d3e2de46ef48e09d3fea2a747fb4ef"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }